import streamlit as st
import json
from langchain.retrievers import WikipediaRetriever
from langchain.text_splitter import CharacterTextSplitter
from langchain.document_loaders import UnstructuredFileLoader
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.callbacks import StreamingStdOutCallbackHandler
from langchain.schema import BaseOutputParser

# íŒŒì¼ì— ëŒ€í•œ ì§ˆë¬¸ì„ í•˜ëŠ” ëŒ€ì‹ ì— LLMì´ ìš°ë¦¬ì—ê²Œ íŒŒì¼ì˜ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•˜ê²Œë” ëª…ë ¹í•  ê²ƒì´ë‹¤.
# Wikipedia Retrieverë¥¼ ì‚¬ìš©
# OutputParserë¥¼ ë°°ìš°ëŠ” ê²ƒì— í¬ì¸íŠ¸ë¥¼ ë‘¬ì•¼ í•œë‹¤.

# Function Calling
# ìš°ë¦¬ê°€ ë§Œë“  í•¨ìˆ˜ê°€ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€, ì–´ë–¤ parameter ê°’ì„ ì›í•˜ëŠ”ì§€ LLMì—ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.
# ê·¸ëŸ° ë’¤ì—” ìš°ë¦¬ê°€ LLMì—ê²Œ ì§ˆë¬¸ì„ í–ˆì„ ë•Œ, LLMì´ textë¡œ ë‹µí•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ ìš°ë¦¬ê°€ ì‘ì„±í•œ í•¨ìˆ˜ë“¤ì„ í˜¸ì¶œí•œë‹¤.
# agentì—ê²Œ LLMì„ ì„¤ëª… -> LLMì€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ -> í˜¸ì¶œì— í•„ìš”í•œ ì¸ìê°’ë“¤ì„ í•¨ìˆ˜ì— ë„£ì–´ì¤€ë‹¤.


st.set_page_config(
    page_title="QuizGPT",
    page_icon="ğŸ’·",
)


class JsonOutputParser(BaseOutputParser):
    def parse(self, text):
        text = text.replace("```", "").replace("json", "")
        return json.loads(text)


output_parser = JsonOutputParser()

llm = ChatOpenAI(
    temperature=0.1,
    model="gpt-3.5-turbo-1106",
    streaming=True,
    callbacks=[StreamingStdOutCallbackHandler()],
)


def format_docs(docs):
    return "\n\n".join(document.page_content for document in docs)


question_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
        AIëŠ” ì„ ìƒë‹˜ ì—­í• ì„ í•´ì£¼ëŠ” í›Œë¥­í•œ ì¡°ìˆ˜ì…ë‹ˆë‹¤.
        
        ì•„ë˜ì˜ ë‚´ìš©ì— ë”°ë¼ ìœ ì €ì˜ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì§€ì‹ì„ íŒë‹¨í•˜ëŠ” ë¬¸ì œ 10ê°œë¥¼ ë§Œë“œì„¸ìš”
        
        ê°ê°ì˜ ì§ˆë¬¸ë“¤ì€ ëª¨ë‘ 4ê°œì˜ ì„ íƒì§€ê°€ ìˆì–´ì•¼ í•˜ê³  ê·¸ ì¤‘ 3ê°œëŠ” ì˜¤ë‹µ 1ê°œëŠ” ì •ë‹µì´ì–´ì•¼ í•©ë‹ˆë‹¤.
        
        (O)ë¬¸ìë¥¼ í†µí•´ ì •ë‹µì„ í‘œì‹œí•˜ë„ë¡ í•©ë‹ˆë‹¤.
        
        ì§ˆë¬¸ ì˜ˆì œ:
        
        
        ì§ˆë¬¸: ë°”ë‹¤ëŠ” ì–´ë–¤ ìƒ‰ì…ë‹ˆê¹Œ?
        
        ì„ íƒì§€s: ë¹¨ê°• | ë…¸ë‘ | ì´ˆë¡ | íŒŒë‘(O)
        
        
        ì§ˆë¬¸: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?
        
        ì„ íƒì§€s: í‰ì–‘ | ë„ì¿„ | ë² ì´ì§• | ì„œìš¸(O)
        
        
        ì§ˆë¬¸: ì•„ë°”íƒ€1ì€ ì–¸ì œ ê°œë´‰í–ˆë‚˜ìš”?
        
        ì„ íƒì§€s: 2009(O) | 2001 | 1998 | 2007
        
        
        ì§ˆë¬¸: ì¤„ë¦¬ì–´ìŠ¤ ì‹œì €ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?
        
        ì„ íƒì§€s: í™”ê°€ | ë¡œë§ˆì˜ í™©ì œ(O) | ë°°ìš° | ì˜ì‚¬
        
        
        ë„ˆì˜ ì°¨ë¡€ì•¼!!
        
        context: {context}
        """,
        )
    ]
)
questions_chain = {"context": format_docs} | question_prompt | llm

formatting_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
    ë‹¹ì‹ ì€ ê°•ë ¥í•œ formatting ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
    
    ë‹¹ì‹ ì€ ì‹œí—˜ ë¬¸ì œë¥¼ json í˜•ì‹ìœ¼ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.
    (O) í‘œì‹œê°€ ìˆëŠ” ë³´ê¸°ê°€ ì •ë‹µì…ë‹ˆë‹¤.
    
    ì§ˆë¬¸ ì˜ˆì œ:
        
        ì§ˆë¬¸: ë°”ë‹¤ëŠ” ì–´ë–¤ ìƒ‰ì…ë‹ˆê¹Œ?
        ì„ íƒì§€s: ë¹¨ê°• | ë…¸ë‘ | ì´ˆë¡ | íŒŒë‘(O)
        
        ì§ˆë¬¸: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?
        ì„ íƒì§€s: í‰ì–‘ | ë„ì¿„ | ë² ì´ì§• | ì„œìš¸(O)
        
        ì§ˆë¬¸: ì•„ë°”íƒ€1ì€ ì–¸ì œ ê°œë´‰í–ˆë‚˜ìš”?
        ì„ íƒì§€s: 2009(O) | 2001 | 1998 | 2007
        
        ì§ˆë¬¸: ì¤„ë¦¬ì–´ìŠ¤ ì‹œì €ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?
        ì„ íƒì§€s: í™”ê°€ | ë¡œë§ˆì˜ í™©ì œ(O) | ë°°ìš° | ì˜ì‚¬
        
        
        ê²°ê³¼ ì˜ˆì‹œ:
        
        '''json
        {{ "questions": [
            {{
                "ì§ˆë¬¸": "ë°”ë‹¤ëŠ” ì–´ë–¤ ìƒ‰ì…ë‹ˆê¹Œ?",
                "ì„ íƒì§€s": [
                    {{
                        "ì„ íƒì§€": "ë¹¨ê°•",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "ë…¸ë‘",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "ì´ˆë¡",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "íŒŒë‘",
                        "ì •ë‹µ": true
                    }},
                ]
            }},
            {{
                "ì§ˆë¬¸": "ëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?",
                "ì„ íƒì§€s": [
                    {{
                        "ì„ íƒì§€": "í‰ì–‘",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "ë„ì¿„",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "ë°°ì´ì§•",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "ì„œìš¸",
                        "ì •ë‹µ": true
                    }},
                ]
            }},
            {{
                "ì§ˆë¬¸": "ì¤„ë¦¬ì–´ìŠ¤ ì‹œì €ëŠ” ëˆ„êµ¬ì…ë‹ˆê¹Œ?",
                "ì„ íƒì§€s": [
                    {{
                        "ì„ íƒì§€": "í™”ê°€",
                        "ì •ë‹µ":false
                    }},
                    {{
                        "ì„ íƒì§€": "ë¡œë§ˆì˜ í™©ì œ",
                        "ì •ë‹µ": true
                    }},
                    {{
                        "ì„ íƒì§€": "ë°°ìš°",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "ì˜ì‚¬",
                        "ì •ë‹µ": false
                    }},
                ]
            }},
            {{
                "ì§ˆë¬¸": "ë°”ë‹¤ëŠ” ì–´ë–¤ ìƒ‰ì…ë‹ˆê¹Œ?",
                "ì„ íƒì§€s": [
                    {{
                        "ì„ íƒì§€": "ë¹¨ê°•",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "ë…¸ë‘",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "ì´ˆë¡",
                        "ì •ë‹µ": false
                    }},
                    {{
                        "ì„ íƒì§€": "íŒŒë‘",
                        "ì •ë‹µ": true
                    }},
                ]
            }},
            
        ]
            
        }}
        '''
        Your turn!

        Questions: {context}
    """,
        )
    ]
)
# {{}} langchainì´ ì´ ë¶€ë¶„ì„ formatí•˜ì§€ ì•Šê¸°ë¥¼ ë°”ë¦¬ê¸° ë•Œë¬¸
# {}: ì–´ë–¤ ê°’ì„ ì£¼ì…í•˜ê³  ì‹¶ì„ ë•Œ ì¤‘ê´„í˜¸ ì‚¬ìš©

formatting_chain = formatting_prompt | llm


st.title("QuizGPT")


# ë‹¨ì§€ tex fileì„ ë„£ì–´ì¤€ë‹¤. -> embed (X)
@st.cache_data(show_spinner="Loading file...")
def split_file(file):
    file_content = file.read()
    file_path = f"./.cache/quiz_files/{file.name}"
    with open(file_path, "wb") as f:
        f.write(file_content)
    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator="\n",
        chunk_size=600,
        chunk_overlap=100,
    )
    loader = UnstructuredFileLoader("./files/chapter_one.txt")
    docs = loader.load_and_split(text_splitter=splitter)
    return docs


@st.cache_data(show_spinner="Making quiz...")
def run_quiz_chain(_docs, topic):
    chain = {"context": questions_chain} | formatting_chain | output_parser
    check = {"context": questions_chain} | formatting_chain
    print(check)
    return chain.invoke(_docs)


@st.cache_data(show_spinner="Searching Wikipedia...")
def wiki_search(term):
    # hash: ë“¤ì–´ì˜¤ëŠ” ë°ì´í„°ì˜ ì„œëª…ì„ ìƒì„±í•œë‹¤ëŠ” ê²ƒ
    retriever = WikipediaRetriever(top_k_results=4, lang="ko")
    # top_k_results=1 : ì²« ë²ˆì§¸ ê²°ê³¼ë§Œ ì‚¬ìš©
    docs = retriever.get_relevant_documents(term)
    return docs


# with st.sidebar:
docs = None
choice = st.selectbox(
    "Choose what you want to use.",
    (
        "File",
        "Wikipedia Article",
    ),
)
if choice == "File":
    file = st.file_uploader(
        "Upload a .docx, .txt or .pdf file", type=["docx", "txt", "pdf"]
    )
    if file:
        docs = split_file(file)
else:
    topic = st.text_input("Search Wikipedia...")
    if topic:
        docs = wiki_search(topic)

if not docs:
    st.markdown(
        """
    QuizeGPTëŠ” Wikipediaì™€ ì‚¬ìš©ìê°€ ì œê³µí•œ íŒŒì¼ì„ ì´ìš©í•´ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ ì œê³µí•©ë‹ˆë‹¤.
    
    ì‚¬ìš©ì„ ì›í•˜ì‹ ë‹¤ë©´ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ Wikipediaì„ ì„ íƒí•´ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.
    """
    )
else:

    # questions_response = questions_chain.invoke(docs)
    # st.write(questions_response.content)
    # # ë¬¸ì„œë¥¼ chainì„ ë¶ˆëŸ¬ì˜¬ ë•Œ ë„˜ê²¨ì£¼ê³  -> format_docsë¡œ ë„˜ì–´ê°„ ë’¤ -> stringì„ ë°˜í™˜í•˜ê³  -> contextì˜ ê°’ì´ ëœë‹¤. -> prompt ì•ˆìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤.
    # formatting_response = formatting_chain.invoke(
    #     {"context": questions_response.content}
    # )
    response = run_quiz_chain(docs, topic if topic else file.name)

    # ì ‘ì—ˆë‹¤ê°€ í´ê¸° ê°€ëŠ¥í•˜ê²Œ
    st.write(response)

    with st.form("questions_form"):
        for question in response["questions"]:
            st.write(question["ì§ˆë¬¸"])
            value = st.radio(
                "Select an option.",
                [ì„ íƒì§€["ì„ íƒì§€"] for ì„ íƒì§€ in question["ì„ íƒì§€s"]],
                index=None,
            )
            if {"ì„ íƒì§€": value, "ì •ë‹µ": True} in question["ì„ íƒì§€s"]:
                st.success("ì •ë‹µ")
            elif value is not None:
                st.error("ì˜¤ë‹µ")
        button = st.form_submit_button()


# ì •ë‹µì„ ì•Œë ¤ì£¼ëŠ” ì½”ë“œ
