{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#RAG(Retriveal-Augmented-Generation): 검색 증강 생성\n",
    "    자연어 처리(NLP) 및 기계 학습 분야, 특히 챗복이나 질문-응답 시스템과 같은 고급 언어 모델을 구축하는 데 사용되는 기술\n",
    "\n",
    "#NLP의 두 가지 주요 구성 요소인 정보 검색과 응답 생성을 결합\n",
    "    검색 부분은 관련 정보를 찾기 위해 대규모 데이터베이스나 문서 컬렉션을 검색하는 과정을 포함\n",
    "    생성 부분은 검색된 정보를 바탕으로 일관되고 맥락적으로 적절한 텍스트를 생성하는 과정\n",
    "\n",
    "#작동 방식\n",
    "    1. 질문이나 프롬프트가 주어지면 모델은 먼저 질문에 대한 답변을 제공하는 데 유용한 정보를 포함할 수 있는 관련 문서나 텍스트를 검색\n",
    "    2. 검색된 정보를 생성 모델에 공급하여 일관된 응답을 합성\n",
    "    => 질문 / 질문을 할 때 저장된 vector에서 단어를 탐색(유, 무 아님) -> 관련 문서를 prompt로 보낸다 -> model로 해당 prompt를 전달\n",
    "\n",
    "#장점:\n",
    "    모델이 외부 지식을 활용할 수 있게 하여 보다 정확하고 상세하며 맥락적으로 관련된 답변을 제공\n",
    "    => 특정 지식이나 사실적 정보가 필요한 질문에 특히 유용\n",
    "\n",
    "#응용 분야:\n",
    "    챗봇, 질문-응답 시스템 및 정확하고 맥락적으로 관련된 정보를 제공하는 것이 중요한 다른 AI 도구와 같은 다양한 응용 분야에 사용\n",
    "    다양한 주제와 데이터를 기반으로 이해하고 응답을 생성해야 하는 상황에서 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data Retrieve\n",
    "    Source -> Load -> Transform -> Embed -> Storage -> Retrieve\n",
    "    소스에서 데이터 load 후, 데이터 분할하며 변환 -> 변환한 데이터를 임베드(텍스트에서 컴퓨터가 이해할 수 있는 숫자로 변환) -> 저장 / 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "# chunk_size=200, chunk_overlap=50\n",
    "# chunk_overlap: 문장이나 문단을 분할할 때 앞 조각 끝 일부분을 가져오게 만든다. -> 중복이 생긴다.\n",
    "# length_function=len: 얼마나 많은 글자가 있는지 세 준다.\n",
    "\n",
    "# loader = TextLoader(\"./files/chapter_one.txt\")\n",
    "# loader = PyPDFLoader(\"./files/chapter_one.pdf\")\n",
    "# docs = loader.load()\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.docx\")\n",
    "\n",
    "# len(loader.load_and_split(text_splitter=splitter))\n",
    "loader.load_and_split(text_splitter=splitter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separators=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    "    \n",
    ")\n",
    "# length_function=len: 얼마나 많은 글자가 있는지 세 준다.\n",
    "# token은 문자와 같은 의미가 아니다 -> 문자 두, 세 개를 한 개의 token으로 취급하기도 한다.\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.docx\")\n",
    "\n",
    "loader.load_and_split(text_splitter=splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors\n",
    "    vecroization(벡터화) / 우리가 만든 문서마다 각각의 벡터를 만든다.\n",
    "    word(단어)에 embed 작업을 한다.\n",
    "\n",
    "Embed\n",
    "    Embedding = 사람이 읽는 텍스트를 컴퓨터가 이해할 수 있는 숫자들로 변환하는 작업\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
