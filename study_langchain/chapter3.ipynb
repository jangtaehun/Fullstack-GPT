{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM = Large language model\n",
    "#### Langchain은 LLM과 Chat model 두 가지를 모두 지원\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMs and Chat Models\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "a = llm.predict(\"행성에 대해 알려줘\")\n",
    "b = chat.predict(\"행성은 뭐가 있어\")\n",
    "\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국과 일본 사이의 거리는 직선거리로 약 900km 정도입니다. 제 이름은 장태훈입니다.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Messages\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "# SystemMessage: 우리가 LLM에 설정들을 제공하기 위한 message\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "# temperature: 얼마나 창의적인가 0~1\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"당신은 지리 전문가야, 당신은 한국어로만 답변해야 합니다.\"),\n",
    "    AIMessage(content=\"안녕하세요. 저는 장태훈입니다.\"),\n",
    "    HumanMessage(content=\"한국과 일본 사이의 거리는 어떻게 되나요? 그리고 당신의 이름은 어떻게 되나요\")\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prompt:  LLM과 의사소통할 수 있는 유일한 방법, 성능이 좋으면 답변도 좋다.\n",
    "-  from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "> - PromptTemplate: string을 이용해 template을 만든다.\n",
    "> - ChatPromptTemplate: message로부터 template을 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'한국과 일본 사이의 거리는 해상 거리로 약 900km 정도이며, 항공편으로는 약 2시간 정도 소요됩니다. \\n\\n제 이름은 AI 어시스턴트입니다. 저를 통해 궁금한 것이 있으면 언제든지 물어봐주세요!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Templates\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessage(content=\"당신은 지리 전문가야, 당신은 {language}로만 답변해야 합니다.\"),\n",
    "#     AIMessage(content=\"안녕하세요. 저는 {name}입니다.\"),\n",
    "#     HumanMessage(content=\"{country_a}과 {country_b} 사이의 거리는 어떻게 되나요? 그리고 당신의 이름은 어떻게 되나요\")\n",
    "# ]\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "template = PromptTemplate.from_template(\"{country_a}과 {country_b} 사이의 거리는 어떻게 되나요? 그리고 당신의 이름은 어떻게 되나요\")\n",
    "prompt = template.format(country_a=\"한국\", country_b=\"일본\")\n",
    "print(prompt)\n",
    "\n",
    "chat.predict(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='당신은 지리 전문가야, 당신은 한국어로만 답변해야 합니다.'), AIMessage(content='안녕하세요. 저는 김쫀떡입니다.'), HumanMessage(content='한국과 일본 사이의 거리는 어떻게 되나요? 그리고 당신의 이름은 어떻게 되나요')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국과 일본 사이의 거리는 직선거리로 약 900km 정도입니다. 제 이름은 김쫀떡입니다.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat Prompt Template\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# list 전달\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 지리 전문가야, 당신은 {language}로만 답변해야 합니다.\"),\n",
    "    (\"ai\", \"안녕하세요. 저는 {name}입니다.\"),\n",
    "    (\"human\", \"{country_a}과 {country_b} 사이의 거리는 어떻게 되나요? 그리고 당신의 이름은 어떻게 되나요\")\n",
    "])\n",
    "prompt = template.format_messages(\n",
    "    language= \"한국어\",\n",
    "    name = \"김쫀떡\",\n",
    "    country_a = \"한국\",\n",
    "    country_b = \"일본\"\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['수성', '금성', '지구', '화성', '목성', '토성', '천왕성', '해왕성']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OutputParser and LCEL\n",
    "# LangChain expression language는 코드를 줄여준다. / 다양한 template과 LLM호출, 서로 다른 응답을 할께 사용하게 해준다.\n",
    "# OutputParser: LLM의 응답을 변해야할 때가 있기 때문에 필요\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 list 생성 기계입니다. 입력받은 질문들은 콤마로 구분해서 최대 {max_items}만큼 list로 답해주세요. list가 아닌 것으로 답하지 마세요.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "prompt = template.format_messages(\n",
    "    max_items = 10,\n",
    "    question = \"행성이 무엇이 있는지 알려줘\"\n",
    ")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain\n",
    "> - chain끼리도 결합할 수 있다.\n",
    "> - - chain_one = template | chat | CommaOutputParser()\n",
    "> - - chain_two = template_2 | chat | CommaOutputParser()\n",
    "> - - all = chain_one | chain_two | CommaOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['포켓몬은 포켓몬스터라고 불리는 가상 생명체들을 일컫는 말입니다.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"max_items\": 5,\n",
    "    \"question\": \"포켓몬이 모야?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
