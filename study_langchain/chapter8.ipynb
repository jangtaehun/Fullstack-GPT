{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jangtaehun/Desktop/study/nomad/Fullstack-GPT/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'’s name?\\n\\nThe cat’s name is “Mittens”.\\n\\nWhat is the cat’s age?\\n\\nThe cat’s age is 10 years old.\\n\\nWhat is the cat’s breed?\\n\\nThe cat’s breed is “Siamese”.\\n\\nWhat is the cat’s weight?\\n\\nThe cat’s weight is 10 pounds.\\n\\nWhat is the cat’s height?\\n\\nThe cat’s height is 10 inches.\\n\\nWhat is the cat’s color?\\n\\nThe cat’s color is “black”.\\n\\nWhat is the cat’s eye color?\\n\\nThe cat’s eye color is “green”.\\n\\nWhat is the cat’s fur color?\\n\\nThe cat’s fur color is “black”.\\n\\nWhat is the cat’s tail length?\\n\\nThe cat’s tail length is 10 inches.\\n\\nWhat is the cat’s ear length?\\n\\nThe cat’s ear length is 10 inches.\\n\\nWhat is the cat’s nose length?\\n\\nThe cat’s nose length is 10'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is the {word}\")\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id = \"mistralai/Mistral-7B-v0.1\",\n",
    "    model_kwargs = {\n",
    "        \"max_new_tokens\": 250\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\":\"cat\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 고양이는 식물의 초기 단계에서 생장하는 것을 의미합니다. 식물이 생장하기 전에 씨가 심어진 것을 고양이라고 합니다. 식물이 생장하기 전에 씨가 심어진 것을 고양이라고 하는 것은 식물이 생장하기 전에 씨가 심어진 것을 의미합니다. 식물이 생장하기 전에 씨가 심어진 것을 고양이라고 하는 것은 식물이 생장하기 전에 씨가 심어진 것을 의미합니다. 식물이 생장하기 전에 씨가 심어진 것을 고양이라고 하는 것은 식물이 생장하기 전에 '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"[INST]{word}의 의미가 무엇인가요?[/INST]\")\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id = \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    model_kwargs = {\n",
    "        \"max_new_tokens\": 250\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\":\"고양이\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' vegetable which produces many different vegetables, but is mainly composed of a variety of other components such as enzymes.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HuggingFacePipeline\n",
    "# GPU가 있다면 falcon 사용하는 것을 시도해 볼 수 있다.\n",
    "\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"A {word} is a\")\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"gpt2\",\n",
    "    task=\"text-generation\",\n",
    "    # device = -1 : cpu / 0 : GPU -> macbook pro에서 작동하지 않는다.\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\":50\n",
    "    },\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\":\"tomato\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
